
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>rai_toolbox.mushin.lightning.launchers &#8212; rai-toolbox  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    
      
      <link rel="icon" sizes="16x16" href="../../../../_static/favicon-16x16.png">
      
    
      
      <link rel="icon" sizes="32x32" href="../../../../_static/favicon-32x32.png">
      
    
      
      <link rel="apple-touch-icon" sizes="180x180" href="../../../../_static/apple-touch-icon.png">
      
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/logo_no_text.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../how_tos.html">
  How-To Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../explanation.html">
  Explanation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../api_reference.html">
  Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../changes.html">
  Changelog
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for rai_toolbox.mushin.lightning.launchers</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022, MASSACHUSETTS INSTITUTE OF TECHNOLOGY</span>
<span class="c1"># Subject to FAR 52.227-11 – Patent Rights – Ownership by the Contractor (May 2014).</span>
<span class="c1"># SPDX-License-Identifier: MIT</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">TypeVar</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">hydra.core.hydra_config</span> <span class="kn">import</span> <span class="n">HydraConfig</span>
<span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <span class="n">load_from_yaml</span>
<span class="kn">from</span> <span class="nn">omegaconf.errors</span> <span class="kn">import</span> <span class="n">ConfigAttributeError</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.states</span> <span class="kn">import</span> <span class="n">TrainerFn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">distributed</span>

<span class="kn">from</span> <span class="nn">.._compatibility</span> <span class="kn">import</span> <span class="n">PL_VERSION</span><span class="p">,</span> <span class="n">Version</span>

<span class="n">R</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;R&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_setup_environment</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
        <span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_teardown</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># Remove PL environments so next multirun starts fresh</span>
    <span class="n">envs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span>
        <span class="s2">&quot;NODE_RANK&quot;</span><span class="p">,</span>
        <span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span>
        <span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">,</span>
        <span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">,</span>
        <span class="s2">&quot;PL_GLOBAL_SEED&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">envs</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_subprocess_call</span><span class="p">(</span><span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">predicting</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">env_copy</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">env_copy</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="c1"># CWD is the Hydra working directory</span>
    <span class="n">cwd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
    <span class="n">os_cwd</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">cwd</span><span class="si">}</span><span class="s1">&quot;&#39;</span>  <span class="c1"># this is needed to handle characters like `=` in the directory name</span>
    <span class="p">)</span>

    <span class="n">command</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span>
        <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rai_toolbox.mushin.lightning._pl_main&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">hydra_cfg</span> <span class="o">=</span> <span class="n">HydraConfig</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

    <span class="n">hydra_output</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="n">hydra_cfg</span><span class="o">.</span><span class="n">output_subdir</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hydra_cfg</span><span class="o">.</span><span class="n">output_subdir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">cwd</span>
    <span class="p">)</span>

    <span class="c1"># Validate that minimal configuration requirements</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">hydra_output</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;config.yaml&quot;</span>
    <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">load_from_yaml</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;trainer&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">or</span> <span class="s2">&quot;module&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">ConfigAttributeError</span><span class="p">(</span>
            <span class="s2">&quot;Missing configurations `trainer` and `module` are required for use with HydraDDP.  See documentation for further details.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># create the command for CLI</span>
    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;-cp&quot;</span><span class="p">,</span> <span class="n">hydra_output</span><span class="p">,</span> <span class="s2">&quot;-cn&quot;</span><span class="p">,</span> <span class="s2">&quot;config.yaml&quot;</span><span class="p">]</span>

    <span class="c1"># Set flag to run Trainer.fit or Trainer.test in `_pl_main.py`</span>
    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;++pl_testing=&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;false&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">testing</span> <span class="k">else</span> <span class="s2">&quot;true&quot;</span><span class="p">)]</span>

    <span class="c1"># Set flag to run Trainer.fit or Trainer.test in `_pl_main.py`</span>
    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;++pl_predicting=&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;false&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">predicting</span> <span class="k">else</span> <span class="s2">&quot;true&quot;</span><span class="p">)]</span>

    <span class="c1"># Set flag for local rank</span>
    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;++pl_local_rank=</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>

    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s2">&quot;hydra.run.dir=</span><span class="si">{</span><span class="n">os_cwd</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="sa">f</span><span class="s2">&quot;hydra.output_subdir=.pl_hydra_rank_</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="sa">f</span><span class="s2">&quot;hydra.job.name=</span><span class="si">{</span><span class="n">hydra_cfg</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env_copy</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">cwd</span><span class="p">)</span>


<span class="k">if</span> <span class="n">PL_VERSION</span> <span class="o">&gt;=</span> <span class="n">Version</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.ddp</span> <span class="kn">import</span> <span class="n">DDPStrategy</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.launchers.subprocess_script</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_SubprocessScriptLauncher</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">class</span> <span class="nc">HydraDDP</span><span class="p">(</span><span class="n">DDPStrategy</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
        <span class="sd">&quot;&quot;&quot;DDP Strategy that supports Hydra run and multirun jobs.</span>

<span class="sd">        This strategy assumes a PyTorch Lightning `Trainer.fit` or `Trainer.test` has been configured</span>
<span class="sd">        to execute via Hydra.  It requires that Hydra saves a `config.yaml` in the current working directory with the following keys/properties set::</span>

<span class="sd">           ├── Config</span>
<span class="sd">           │    ├── trainer: A `pytorch_lightning.Trainer` configuration</span>
<span class="sd">           │    ├── module: A `pytorch_lightning.LightningModule` configuration</span>
<span class="sd">           │    ├── datamodule: [OPTIONAL] A `pytorch_lightning.LightningDataModule` configuration</span>

<span class="sd">        This strategy will launch a child subprocesses for additional GPU beyond the first using the following base command::</span>

<span class="sd">           python -m rai_toolbox.mushin.lightning._pl_main -cp &lt;path to config.yaml&gt; -cn config.yaml</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        First define a Hydra configuration using hydra-zen:</span>

<span class="sd">        &gt;&gt;&gt; import pytorch_lightning as pl</span>
<span class="sd">        ... from hydra_zen import builds, make_config,</span>
<span class="sd">        ... from rai_toolbox.mushin import HydraDDP</span>
<span class="sd">        ... from rai_toolbox.mushin.testing.lightning import SimpleLightningModule</span>
<span class="sd">        ...</span>
<span class="sd">        ... TrainerConfig = builds(</span>
<span class="sd">        ...     pl.Trainer,</span>
<span class="sd">        ...     accelerator=&quot;auto&quot;,</span>
<span class="sd">        ...     gpus=2,</span>
<span class="sd">        ...     max_epochs=1,</span>
<span class="sd">        ...     fast_dev_run=True,</span>
<span class="sd">        ...     strategy=builds(HydraDDP),</span>
<span class="sd">        ...     populate_full_signature=True</span>
<span class="sd">        ... )</span>
<span class="sd">        ...</span>
<span class="sd">        ... ModuleConfig = builds(SimpleLightningModule)</span>
<span class="sd">        ...</span>
<span class="sd">        ... Config = make_config(</span>
<span class="sd">        ...     trainer=TrainerConfig,</span>
<span class="sd">        ...     module=ModuleConfig</span>
<span class="sd">        ... )</span>

<span class="sd">        Next, define a task function to execute the Hydra job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import instantiate</span>
<span class="sd">        &gt;&gt;&gt; def task_function(cfg):</span>
<span class="sd">        ...     obj = instantiate(cfg)</span>
<span class="sd">        ...     obj.trainer.fit(obj.module)</span>

<span class="sd">        Launch the Hydra+Lightning DDP job</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import launch</span>
<span class="sd">        &gt;&gt;&gt; job = launch(Config, task_function)</span>

<span class="sd">        ``HydraDDP`` also supports ``LightningDataModule`` configuration.</span>

<span class="sd">        &gt;&gt;&gt; DataModuleConfig = ... # A LightningDataModule config</span>
<span class="sd">        &gt;&gt;&gt; Config = make_config(</span>
<span class="sd">        ...     trainer=TrainerConfig,</span>
<span class="sd">        ...     module=ModuleConfig</span>
<span class="sd">        ...     datamodule=DataModuleconfig</span>
<span class="sd">        ... )</span>

<span class="sd">        Next define a task function to execute the Hydra job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import instantiate</span>
<span class="sd">        &gt;&gt;&gt; def task_function(cfg):</span>
<span class="sd">        ...     obj = instantiate(cfg)</span>
<span class="sd">        ...     obj.trainer.fit(obj.module, datamodule=obj.datamodule)</span>

<span class="sd">        Launch the Hydra+Lightning DDP job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import launch</span>
<span class="sd">        &gt;&gt;&gt; job = launch(Config, task_function)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">setup_environment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_setup_environment</span><span class="p">()</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_environment</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_configure_launcher</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;HydraDDP.cluster_environment is None&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">creates_processes_externally</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_launcher</span> <span class="o">=</span> <span class="n">_HydraDDPLauncher</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_rank_0_will_call_children_scripts</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Performs additional teardown steps for PL to allow for Hydra multirun jobs.&quot;&quot;&quot;</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
            <span class="n">_teardown</span><span class="p">()</span>

    <span class="k">class</span> <span class="nc">_HydraDDPLauncher</span><span class="p">(</span><span class="n">_SubprocessScriptLauncher</span><span class="p">):</span>
        <span class="nd">@property</span>
        <span class="k">def</span> <span class="nf">is_interactive_compatible</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">def</span> <span class="nf">launch</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">R</span><span class="p">],</span>
            <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Creates new processes, then calls the given function.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            function : Callable[[...], ReturnType]</span>
<span class="sd">                A callback function to execute after all processes have been created.</span>
<span class="sd">                It is up to the implementation of this function to synchronize the processes, e.g., with barriers.</span>

<span class="sd">            *args : Any</span>
<span class="sd">                Optional positional arguments to be passed to the given function.</span>

<span class="sd">            trainer : pytorch_lightning.Trainer</span>
<span class="sd">                Optional reference to the pytorch_lightning.Trainer`.</span>

<span class="sd">            **kwargs : Any</span>
<span class="sd">                Optional keyword arguments to be passed to the given function.</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            ReturnType</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">del</span> <span class="n">trainer</span>  <span class="c1"># unused</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">creates_processes_externally</span>
            <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
                <span class="n">testing</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;_test_impl&quot;</span>
                <span class="n">predicting</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;_predict_impl&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_call_children_scripts</span><span class="p">(</span><span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">,</span> <span class="n">predicting</span><span class="o">=</span><span class="n">predicting</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_call_children_scripts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">predicting</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="c1"># bookkeeping of spawned processes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_can_spawn_children</span><span class="p">()</span>

            <span class="c1"># DDP Environment variables</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">main_address</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">main_port</span><span class="p">)</span>

            <span class="c1"># allow the user to pass the node rank</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;NODE_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">node_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">for</span> <span class="n">local_rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">):</span>
                <span class="n">_subprocess_call</span><span class="p">(</span><span class="n">local_rank</span><span class="p">,</span> <span class="n">testing</span><span class="p">,</span> <span class="n">predicting</span><span class="p">)</span>

                <span class="c1"># starting all processes at once can cause issues</span>
                <span class="c1"># with dataloaders delay between 1-10 seconds</span>
                <span class="n">delay</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.plugins.training_type.ddp</span> <span class="kn">import</span> <span class="n">DDPPlugin</span>

<div class="viewcode-block" id="HydraDDP"><a class="viewcode-back" href="../../../../generated/rai_toolbox.mushin.HydraDDP.html#rai_toolbox.mushin.HydraDDP">[docs]</a>    <span class="k">class</span> <span class="nc">HydraDDP</span><span class="p">(</span><span class="n">DDPPlugin</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;DDP Strategy that supports Hydra run and multirun jobs.</span>

<span class="sd">        This strategy assumes a PyTorch Lightning `Trainer.fit` or `Trainer.test` has been configured</span>
<span class="sd">        to execute via Hydra.  It requires that Hydra saves a `config.yaml` in the current working directory with the following keys/properties set::</span>

<span class="sd">           ├── Config</span>
<span class="sd">           │    ├── trainer: A `pytorch_lightning.Trainer` configuration</span>
<span class="sd">           │    ├── module: A `pytorch_lightning.LightningModule` configuration</span>
<span class="sd">           │    ├── datamodule: [OPTIONAL] A `pytorch_lightning.LightningDataModule` configuration</span>

<span class="sd">        This strategy will launch a child subprocesses for additional GPU beyond the first using the following base command::</span>

<span class="sd">           python -m rai_toolbox.mushin.lightning._pl_main -cp &lt;path to config.yaml&gt; -cn config.yaml</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        First define a Hydra configuration using hydra-zen:</span>

<span class="sd">        &gt;&gt;&gt; import pytorch_lightning as pl</span>
<span class="sd">        ... from hydra_zen import builds, make_config,</span>
<span class="sd">        ... from rai_toolbox.mushin import HydraDDP</span>
<span class="sd">        ... from rai_toolbox.mushin.testing.lightning import SimpleLightningModule</span>
<span class="sd">        ...</span>
<span class="sd">        ... TrainerConfig = builds(</span>
<span class="sd">        ...     pl.Trainer,</span>
<span class="sd">        ...     accelerator=&quot;auto&quot;,</span>
<span class="sd">        ...     gpus=2,</span>
<span class="sd">        ...     max_epochs=1,</span>
<span class="sd">        ...     fast_dev_run=True,</span>
<span class="sd">        ...     strategy=builds(HydraDDP),</span>
<span class="sd">        ...     populate_full_signature=True</span>
<span class="sd">        ... )</span>
<span class="sd">        ...</span>
<span class="sd">        ... ModuleConfig = builds(SimpleLightningModule)</span>
<span class="sd">        ...</span>
<span class="sd">        ... Config = make_config(</span>
<span class="sd">        ...     trainer=TrainerConfig,</span>
<span class="sd">        ...     module=ModuleConfig</span>
<span class="sd">        ... )</span>

<span class="sd">        Next define a task function to execute the Hydra job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import instantiate</span>
<span class="sd">        &gt;&gt;&gt; def task_function(cfg):</span>
<span class="sd">        ...     obj = instantiate(cfg)</span>
<span class="sd">        ...     obj.trainer.fit(obj.module)</span>

<span class="sd">        Launch the Hydra+Lightning DDP job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import launch</span>
<span class="sd">        &gt;&gt;&gt; job = launch(Config, task_function)</span>

<span class="sd">        ``HydraDDP`` also supports ``LightningDataModule`` configuration.</span>

<span class="sd">        &gt;&gt;&gt; DataModuleConfig = ... # A LightningDataModule config</span>
<span class="sd">        &gt;&gt;&gt; Config = make_config(</span>
<span class="sd">        ...     trainer=TrainerConfig,</span>
<span class="sd">        ...     module=ModuleConfig</span>
<span class="sd">        ...     datamodule=DataModuleconfig</span>
<span class="sd">        ... )</span>

<span class="sd">        Next, define a task function to execute the Hydra job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import instantiate</span>
<span class="sd">        &gt;&gt;&gt; def task_function(cfg):</span>
<span class="sd">        ...     obj = instantiate(cfg)</span>
<span class="sd">        ...     obj.trainer.fit(obj.module, datamodule=obj.datamodule)</span>

<span class="sd">        Launch the Hydra+Lightning DDP job:</span>

<span class="sd">        &gt;&gt;&gt; from hydra_zen import launch</span>
<span class="sd">        &gt;&gt;&gt; job = launch(Config, task_function)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">setup_environment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_setup_environment</span><span class="p">()</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_environment</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_call_children_scripts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;HydraDDP.lightning_module is None&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;HydraDDP.lightning_module.trainer is None&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;HydraDDP.cluster_environment is None&quot;</span><span class="p">)</span>

            <span class="c1"># bookkeeping of spawned processes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_can_spawn_children</span><span class="p">()</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># DDP Environment variables</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">master_address</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">master_port</span><span class="p">())</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># allow the user to pass the node rank</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;NODE_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">node_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">interactive_ddp_procs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">local_rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">):</span>
                <span class="n">testing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">TESTING</span>
                <span class="n">predicting</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">PREDICTING</span>
                <span class="p">)</span>
                <span class="n">_subprocess_call</span><span class="p">(</span><span class="n">local_rank</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">,</span> <span class="n">predicting</span><span class="o">=</span><span class="n">predicting</span><span class="p">)</span>

                <span class="c1"># starting all processes at once can cause issues</span>
                <span class="c1"># with dataloaders delay between 1-10 seconds</span>
                <span class="n">delay</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_rank_0_has_called_call_children_scripts</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Performs additional teardown steps for PL to allow for Hydra multirun jobs.&quot;&quot;&quot;</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
            <span class="n">_teardown</span><span class="p">()</span></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022 Massachusetts Institute of Technology.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>